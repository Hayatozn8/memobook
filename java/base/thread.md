<span id="catalog"></span>
- [并发编程的问题](#并发编程的问题)
- [Java并发机制的底层实现原理](#Java并发机制的底层实现原理)
    - [volatile的原理与应用](#volatile的原理与应用)
    - [synchronized的原理与应用](#synchronized的原理与应用)
    - [Java对象头](#Java对象头)
    - [锁的升级与对比](#锁的升级与对比)
    - [原子操作的实现原理]](#原子操作的实现原理)
- [Java内存模型](#java内存模型)
    - [Java内存模型基础](#Java内存模型基础)
- [](#)
- [](#)
- [](#)

# 并发编程的问题
[top](#catalog)
- 上下文切换
    - 如何减少上下文切换
        - 无锁并发编程
            - 多线程竞争锁时，会引起上下文切换
            - 避免方法，如：将数据的ID按照Hash算法取模分段，不同的哦线程处理不同段的数据
        - CAS算法
            - Java的Atomic包使用CAS算法来更新数据，不需要加锁
        - 使用最少线程
        - 使用协程
            - 在单线程里实现多任务的调度，并在单线程里维持多个任务间的任务切换
- 死锁
    - 避免死锁的几种方法
        - 避免在一个线程同时获取多个锁
        - 避免在一个线程在锁内占用多个资源，尽量保证每个锁只占用一个资源
        - 尝试使用定时锁，使用`lock.tryLock(timeout)`来替代使用内部锁机制
        - 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况
- 资源限制
    - 资源限制是指：在并发编程时，程序的执行速度受限于计算机硬件资源或软件资源
    - 硬件资源
        - 宽带的上传/下载速度
        - 硬盘读写速度
        - CPU的处理速度
    - 软件资源，如：
        - 数据库的连接数
        - socket连接数
    - 资源限制导致的问题
        - 多线程受限于资源，仍然在串行执行
        - 由于增加了上下文切换和资源调度，导致执行变慢
    - 如何解决资源受限
        - 对于硬件资源限制
            - 使用集群并行执行程序
                - 如通过`数据ID % 机器数`来得到一个机器编号，然后有对应的机器来执行
        - 对于软件资源限制
            - 可以使用资源池来**复用资源**，如：
                - 使用连接池来复用数据库和socket连接
                - 在调用对方webservice接口获取数据时，只建立一个连接
    - 如何在资源限制情况下进行并发编程
        - 根据不同的资源限制调整程序的并发度

# Java并发机制的底层实现原理
[top](#catalog)
- java代码的运行
    1. java代码-->编译-->java字节码
    2. java字节码-->类加载器-->加载到JVM
    3. JVM执行字节码-->汇编指令-->在CPU上执行
- java中使用的并发机制依赖于jvm的实现和cpu指令

## volatile的原理与应用
[top](#catalog)
- `volatile`的基本概念
    - 是轻量级的`synchronized`
    - 在多处理器开发中保证了共享变量的可见性
    - 可见性：当一个线程修改一个共享变量时，另一个线程能读到这个修改后的值
    - **不会引起线程上下文的切换和调度**
        - 如果使用得当，它比`synchronized`的使用和执行成本更低

- 一些CPU术语

|术语|英文|描述|
|-|-|-|
|内存屏障|memory barriers|是一组处理器指令，用于实现对内存操作的顺序限制|
|缓存行|cache line|缓存中可以分配的最小存储单位。处理器填写缓存线时会加载整个缓存线，需要使用多个主内存读周期|
|原子操作|atomic operations|不可中断的一个或一系列操作|
|缓存行填充|cache line fill|当处理器识别到从内存中读取操作数是可缓存的，处理器读取整个缓存行到适当的缓存（L1，L2，L3 或所有）|
|缓存命中|cache hit|如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的地址时，处理器从缓存中读取操作数，而不是从内存读取|
|写命中|write hit|当处理器将操作数写回到一个内存缓存的区域时，它首先会检查这个缓存的内存地址是否在缓存行中，如果存在一个有效的缓存行，则处理器将这个操作数写回到缓存，而不是写回到内存，这个操作被称为写命中|
|写缺失|write misses the cache|一个有效的缓存行被写入到不存在的内存区域|

- `volatile`的定义与实现原理
    - 如果一个字段被声明成`volatile`，Java线程内存模型确保**所有线程看到这个变量的值是一致的**
    - 对`volatile`修饰的共享变量进行写操作时，在汇编代码中会多出一行`lock`代码
        - Lock的操作
            - 将当前处理器缓存行的数据写回到系统内存
            - 写回操作会使其他CPU核心中缓存了该内存地址的数据无效化
    - `volatile`的两条原则
        - Lock前缀指令会引起处理器缓存回写到内存
        - 一个处理器的缓存回写到内存会导致其他处理器的缓存无效
- `volatile`的使用优化
    - `LinkedTransferQueue`，通过追加字节的方式来优化性能
        - 追加字节到64个字节，15个填充对象+当前对象自身，共64字节，一次读取填满一个缓存行
        - 填满后，即头节点占满了一个缓存行，进行入队和出队操作时，就可以避免在一个缓存行中不停的修改数据，而其他处理器不能访问的问题，提高了多处理器下的性能

    - 不是所有的`volatile`变量都应该追加到64字节
        - 缓存行不是64字节的处理器
        - 共享变量不会被频繁地写
            - 追加字节的方式需要处理器读取更多的字节到高速缓存区，这本身就会带来一定的性能消耗
            - 如果共享变量不会被频繁地写，锁的几率也非常小，就没有必要通过追加字节来避免相互锁定

    - 追加字节的方式在Java7中下可能不生效
        - Java7会淘汰或重新排列无用字段，需要使用其他追加字节的方式


## synchronized的原理与应用
[top](#catalog)
- `JavaSE 1.6`对`synchronized`进行了优化，有些情况下不再是`重量级锁`
    - 减少`获取锁/释放锁`带来的性能消耗的优化
        - 引入`偏向锁`和`轻量级锁`
        - 锁的存储结构和升级过程 ???????????????/
- `synchronized`实现同步的基础:Java中的每一个对象都可以作为锁，表现为3点
    1. `synchronized`方法，锁是当前实例对象
    2. `synchronized`类，锁是当前类的Class对象?????????
    3. `synchronized`代码块，锁是`()`中配置的对象

- 访问同步代码时，必须先得到锁，**退出或抛出异常时必须释放锁**

- `synchronized`**在JVM中的实现原理**
    - JVM基于进入和退出`Monitor`对象的方式来实现`方法同步`和`代码块同步`  ????????????????Monitor对象
        - 但方法和代码块的实现细节不一样

    - JVM的实现
        - 代码块同步使用： `monitorenter`, `monitorexit`指令实现
        - 方法同步的实现细节在JVM规范中没有详细说明
            - 方法同步也可以使用`monitorenter`和`monitorexit`指令实现
        - `monitorenter`指令是在**编译后**插入到同步代码块的开始位置
        - `monitorexit`指令是在**编译后**插入到同步代码块的结束位置和异常位置

    - 加锁的过程
        - 前提：
            - JVM会保证**每个monitorenter必须有对应的monitorexit**
            - 任何对象都有一个`monitor`与之关联

        - 当一个`monitor`被持有后，它将处于锁定状态
        - 线程执行到`monitorenter`指令时，会尝试获取对象所对应的`monitor`的所有权，即**尝试获得对象的锁**

- `synchronized`用的锁存在Java对象头中


## Java对象头
[top](#catalog)
- 对象头的内容
    - 如果对象是数组类型，则使用3个字宽；非数组类型，用2个字段

    |长度|内容|说明|
    |-|-|-|
    |32/64bit|Mark Word|存储对象的hashCode或锁信息等|
    |32/64bit|Class Metadata Address|存储到对象类型数据的指针|
    |32/32bit|Array length|数组的长度(如果当前对象是数组)|

- `Mark Word`的存储内容(32位JVM) ?????64位????????????

## 锁的升级与对比
[top](#catalog)
- JavaSE1.6为了减少获得锁和释放锁带来的性能消耗，引入了：`偏向锁`、`轻量级锁`
- JavaSE1.6中锁的状态
    - 4种状态**从低到高**
        1. 无锁状态
        2. 偏向锁状态
        3. 轻量级锁状态
        4. 重量级锁状态
    - 锁的状态会随着竞争情况逐渐升级
    - 锁**可以升级但不能降级**
        - 这种策略是为了**提高获得锁和释放锁的效率**
- 偏向锁
    - 大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入的偏向锁
    - 偏向锁的获得过程
        - 一个线程访问同步块并获得锁时
            - 在对象头和栈帧中的`锁记录`中存储：锁偏向的线程ID
        - 之后再进入同步块时，测试对象头的`Mark Word`中是否存储：**指向当前线程的偏向锁**
            - 不需要使用CAS操作来加锁/解锁
            - 测试成功则获得锁
            - 测试失败，则再测试`Mark Word`中偏向锁的标识是否为`1`(表示当前是偏向锁)
                - 如果` ！= 1`，使用CAS竞争锁
                - 如果` = 1`，尝试使用CAS将对象头的偏向锁指向当前线程
    - 偏向锁的撤销 ????????????????
        - 偏向锁使用了一种等待竞争出现才释放锁的机制，当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁
        - 偏向锁的撤销需要等待全局安全点，即该时点上没有正在执行的字节码
        - 撤销过程
            - 暂停拥有偏向锁的线程
            - 检查持有偏向锁的线程是否活着
                - 线程不活动，将对象头设置成无锁状态
                - 线程活动，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的`Mark Word`要么重新偏向与其他线程，要么恢复到无锁或标记对象不适合作为偏向锁
            - 唤醒暂停的线程
    - 关闭偏向锁
        - 偏向锁在Java6、Java7中默认是启用的，是在应用程序启动几秒之后才激活
            - 可以通过JVM参数来关闭延迟：`-XX:BiasedLockingStartupDelay=0`
        - 如果确定应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁：`-XX:UseBiasedLocking=false`
            - 程序默认会进入轻量级锁状态
- 轻量级锁
    - 加锁（执行同步块之前）
        - 开辟`锁记录空间`: 在当前线程的`栈帧`开辟`锁记录`的空间
        - `Displaced Mark Word`：将对象头中的`Mark Word`复制到锁记录中
        - 替换`Mark Word`: 线程尝试使用CAS将对象头中的`Mark Word`替换为指向`锁记录`的指针
            - 替换成功，当前线程获得锁
            - 替换失败，表示其他线程竞争锁，当前线程使用`自旋锁`来获取锁
    - 解锁
        - 使用原子的CAS操作将`Displaced Mark Word`替换到对象头
            - 如果成功，表示没有竞争发生
            - 如果失败，表示当前锁存在竞争，锁会**膨胀为重量级锁**  ???????????????????
    - 自旋锁会消耗CPU，为了避免无用的自旋(如获得锁的线程被阻塞了)，锁升级为重量级锁
        - 处于重量级锁时，其他视图获取锁的线程都会被阻塞
        - 当持有锁的线程释放锁之后，会唤醒被阻塞线程，这些线程开始重新竞争

- 锁的对比

    |类型|优点|确定|适用场景|
    |-|-|-|-|
    |偏向锁|加锁、解锁不需要额外的CPU消耗，和执行非同步方法相比仅存在纳秒级的差距|如果线程间存在锁竞争，会带来额外的锁撤销消耗|适用于只有一个线程访问同步块|
    |轻量级锁|竞争的线程不会阻塞，提供了程序的响应速度|如果始终得不到锁竞争的线程，会使用自旋锁消耗CPU|追求响应时间、同时块执行速度非常块|
    |重量级锁|线程竞争不使用自旋锁，不会消耗CPU|线程阻塞，响应时间缓慢|追求吞吐量、同步块执行较慢|

## 原子操作的实现原理
[top](#catalog)
- 原子操作：不可中断的一个或一系列操作
- 处理器上的实现原理
    - 一些概念

        |术语|英文|解释|
        |-|-|-|
        |缓存行|Cache line|缓存的最小操作单位|
        |比较并交换(CAS操作)|Compare and Swap|两个参数：新值、旧值，if 变量==旧值，set 变量=新值|
        |CPU流水线|CPU pipeline|CPU中由5～6个不同功能的电路单元组成一条指令处理流水线，然后将一条X86指令分成5～6步后再由这些电路单元分别执行，来实现在一个CPU时钟周期内完成一条指令，提供CPU的运算速度|
        |内存顺序冲突|Memory order violation|一般由假共享引起，假共享指多个CPU同时修改同一个缓存行的不同部分而引起其中一个CPU的操作无效，当出现这个内存顺序冲突时，CPU必须清空流水线|

    - 处理器如何实现原子操作
        - 处理器会自动保证基本的内存操作的原子性
            - 处理器从内存中读取/写入一个字节是原子的，即一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址
        - 复杂的内存操作，处理器提供`总线锁定`和`缓存锁定`两个机制来保证复杂内存操作的原子性
            - 如：跨总线宽度、跨多个缓存行、跨页表的访问
            - `总线锁定`
                - `总线锁定`: 使用处理器提供的一个`LOCK#`信号，当一个处理器在总线上输出此信号时，其他处理器的请求被阻塞住，使该处理器可以独占共享内存
                - 解决的问题
                    - 多个处理器同时对共享变量进行`读改写`操作(如`i++`)，可能会导致计算结果与期望值不符
                        - 如两次`i++`，分别在两个CPU中执行，结果肯为2，不是3
                    - 通过总线锁，保证CPU1操作共享变量时，CPU2不能操作缓存了该共享变量内存地址的缓存
                - 缺点
                    - `总线锁定`会阻塞CPU和内存之间的通信
                    - 锁定期间，其他处理器不能操作其他内存地址的数据，使得**总线锁的开销比较大**

            - `缓存锁定`
                - `缓存锁定`：内存区域如果被缓存在处理器的缓存行中，并且在`Lock`操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言`LOCK#`信号，而是**修改内部的内存地址**，并允许它的缓存一致性机制来保证操作的原子性
                    - 缓存一致性机制会阻止同时修改两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效

                - 在某些情况下，处理器使用`缓存锁定`来替代`总线锁定`来优化
                - 频繁使用的内存会缓存在处理器的L1，L2，L3高速缓存中，原子操作就可以直接在处理器内部缓存中进行，不需要`总线锁定`
                - 两种情况不使用`缓存锁定`
                    1. 被操作数据不能被缓存在处理器内部，或操作的数据跨多个缓存行时，处理器会使用`总线锁定`
                    2. 有些处理器不支持`缓存锁定`

- Java的实现原理
    - Java中通过`锁`和`循环/自旋CAS`的方式来实现原子操作
    - 使用`循环/自旋CAS`实现原子操作
        - JVM中的CAS操作使用处理器提供的`COMPXCHG`指令实现
        - 基本思路：循环进行CAS操作直到成功为止
        - CAS实现原子操作的3大问题
            1. ABA问题
                - CAS会检查值有没有发生变化
                - 如果一个值是`A`，变成了`B`，有变成了`A`，CAS在运行时可能会认为**没有发生变化**，但实际是变化了
                - 解决方法：使用版本号
                    - 在变量前添加版本号：1A->2B->3A
                    - 从JDK1.5开始，`Atomic`包里提供了一个`AtomicStampedReference`来解决ABA问题
            2. 循环时间长开销大
                - 如果`自旋CAS`长时间不成功，会给CPU带来非常大的执行开销
                    - 如果JVM能支持处理器提供的`pause指令`，那么效率会有一定提升
                    - `pause指令`的作用
                        1. 延迟流水线执行和资料，使CPU不会消耗过多的执行资源，延迟时间取决于具体实现版本，一些处理器的延迟时间是0
                        2. 避免退出循环时因内存顺序冲突而引起CPU流水线被清空，来提高CPU的执行效率
            3. 只能保证一个共享变量的原子操作
                - 对多个共享变量时操作时，`循环CAS`无法保证操作的原子性
                - 可以使用锁来解决
                - 可以将多个共享变量合成一个
                    - JDK1.5开始，提供了`AtomicReference`来保证引用对象之间的原子性，可以把多个变量放在一个对象里进行CAS操作
    - 使用`锁`实现原子操作
        - 除了偏向锁，JVM实现锁的方式都用了`循环CAS`
            - 即当一个线程想进入同步块的时候使用`循环CAS`获取锁，退出时使用`循环CAS`释放锁


# Java内存模型
## Java内存模型基础
[top](#catalog)
- 并发编程模型的两个关键问题
    1. 线程之间如何通信/交换信息
        - 两通信机制
            - 共享内存
                - 通过对象内存中的公共状态来进行`隐式通信`
            - 消息传递
                - 线程间通过发送消息来进行`显示通信`
    2. 线程之间如何同步
        - 同步：`程序中用于控制不同线程间操作发生相对顺序的机制`
        - 共享内存机制下，同步是显示的，必须通过方法或指令来使线程互斥
        - 消息传递机制下，同步是隐式的，
- Java采用**共享内存模型**
- Java内存模型的抽象结构
    - Java的所有实例域、静态域、数组元素都存储在堆内存中，**堆内存在线程之间共享**
    - 局部变量、方法参数、异常处理器参数不会在线程之间共享，**没有内存可见性问题，也不受内存模型的影响**
    - JMM
        - Java线程之间的通信由Java内存模型(JMM)控制
        - JMM定义了线程和主内存之间的抽象关系：
            - 线程之间的共享变量存储在`主内存(Main Memory)`中
            - 每个线程都有一个私有的`本地内存(Local Memory)`，本地内存中存储了**该线程读/写共享变量的副本**
                - 本地内存是JMM的一个**抽象概念**，不是真实存在
                    - 它包含了：缓存、写缓冲区、寄存器、其他的硬件和编译器优化
        - JMM通过控制`主内存`与每个线程的`本地内存`之间的交互，来提供内存可见性的保证
    - JMM的抽象示意图??????????
        - 线程A、线程B的通信过程
            1. A把本地内存中更新过的共享变量刷新到主内存中
            2. B从主内存中读取由A更新过的共享变量
    




[top](#catalog)
